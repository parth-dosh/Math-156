{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 3 - Parth Doshi, UID - 805623259"
      ],
      "metadata": {
        "id": "gia6kZB4qsSN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BtDIKzuP91P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "pfGdgsr9k55S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def cross_entropy_loss(y, t):\n",
        "    return -np.mean(t * np.log(y) + (1 - t) * np.log(1 - y))\n"
      ],
      "metadata": {
        "id": "P_3jdYbfQDC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate, batch_size, max_iters):\n",
        "      # required hyperparameters\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.max_iters = max_iters\n",
        "\n",
        "    def fit(self, X, t):\n",
        "        N, D = X.shape\n",
        "        # initialize weights to 0s\n",
        "        self.w = np.zeros(D)\n",
        "\n",
        "        for i in range(self.max_iters):\n",
        "            # shuffle rows\n",
        "            indices = np.arange(N)\n",
        "            np.random.shuffle(indices)\n",
        "            self.w = np.random.randn(D)\n",
        "            # loop through the batch size\n",
        "            for start_idx in range(0, N, self.batch_size):\n",
        "                end_idx = min(start_idx + self.batch_size, N)\n",
        "                # obtain the batch indices\n",
        "                batch_indices = indices[start_idx:end_idx]\n",
        "                # feature batch\n",
        "                X_batch = X[batch_indices]\n",
        "                # target batch\n",
        "                t_batch = t[batch_indices]\n",
        "\n",
        "                y_batch = sigmoid(np.dot(X_batch, self.w))\n",
        "\n",
        "                # average gradient of each batch\n",
        "                gradient = np.dot(X_batch.T, (y_batch - t_batch)) / len(t_batch)\n",
        "\n",
        "                # Update weights\n",
        "                self.w -= self.learning_rate * gradient\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "      # probabilities\n",
        "        return sigmoid(np.dot(X, self.w))\n",
        "\n",
        "    def predict(self, X):\n",
        "      # class label\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
        "\n",
        "    def accuracy(self, X, t):\n",
        "      \"\"\"\n",
        "\n",
        "      Compute the accuracy of the model on a given dataset.\n",
        "\n",
        "      Parameters:\n",
        "      X (array): The input features.\n",
        "      t (array): The target labels.\n",
        "\n",
        "      Returns:\n",
        "      accuracy (float): The accuracy of the model.\n",
        "      \"\"\"\n",
        "      predictions = self.predict(X)\n",
        "      return np.mean(predictions == t)\n",
        "\n",
        "    def confusion_mat(self, y_true, y_pred):\n",
        "      \"\"\"\n",
        "      Compute the confusion matrix for binary classification.\n",
        "\n",
        "      Parameters:\n",
        "      y_true (array-like): The true binary labels (0 or 1).\n",
        "      y_pred (array-like): The predicted binary labels (0 or 1).\n",
        "\n",
        "      Returns:\n",
        "      TP (int): True Positives\n",
        "      FP (int): False Positives\n",
        "      FN (int): False Negatives\n",
        "      TN (int): True Negatives\n",
        "      \"\"\"\n",
        "      TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "      TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "      FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "      FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "      return TP, FP, FN, TN\n",
        "\n",
        "    def precision_recall_f1(self, y_true, y_pred):\n",
        "      \"\"\"\n",
        "      Compute the precision, recall, and F1-score for binary classification.\n",
        "      Parameters:\n",
        "      y_true (array-like): The true binary labels (0 or 1).\n",
        "      y_pred (array-like): The predicted binary labels (0 or 1).\n",
        "      Returns:\n",
        "      precision (float): The precision value.\n",
        "      recall (float): The recall value.\n",
        "      f1 (float): The F1-score value.\n",
        "      \"\"\"\n",
        "      TP, FP, FN, TN = self.confusion_mat(y_true, y_pred)\n",
        "\n",
        "      # Precision\n",
        "      precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "      # Recall\n",
        "      recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "      # F1-Score\n",
        "      f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "      return precision, recall, f1\n",
        "\n",
        "    def evaluate(self, X, t):\n",
        "      \"\"\"\n",
        "      Evaluate the model on a given dataset.\n",
        "\n",
        "      Parameters:\n",
        "      X (array): The input features.\n",
        "      t (array): The target labels.\n",
        "\n",
        "      Returns:\n",
        "      loss (float): The cross-entropy loss\n",
        "      accuracy (float): The accuracy of the model\n",
        "      precision (float): The precision of the model\n",
        "      recall (float): The recall of the model\n",
        "      f1 (float): The F1-score of the model\n",
        "      \"\"\"\n",
        "      y_pred = self.predict(X)\n",
        "      y_prob = self.predict_proba(X)\n",
        "\n",
        "      loss = cross_entropy_loss(y_prob, t)\n",
        "      accuracy = self.accuracy(X, t)\n",
        "\n",
        "      precision, recall, f1 = self.precision_recall_f1(t, y_pred)\n",
        "\n",
        "      return loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "6DjhAhe3RnDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "Tgbl_yIdk-VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a"
      ],
      "metadata": {
        "id": "eTRC05tOTpYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "cancer = load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "AyQ9jOfPUbOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b"
      ],
      "metadata": {
        "id": "ZwsetYOiTq2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the training data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same transformation to validation and test data\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "-kVni5XcUxWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c"
      ],
      "metadata": {
        "id": "V8zBPTnUTuYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_combined = np.concatenate([y_train, y_val])\n",
        "\n",
        "# Report the size of each class\n",
        "class_0_count = sum(y_train_combined == 0)\n",
        "class_1_count = sum(y_train_combined == 1)\n",
        "\n",
        "print(f\"Class 0 count in training + validation set: {class_0_count}\")\n",
        "print(f\"Class 1 count in training + validation set: {class_1_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TKrB1mElWId",
        "outputId": "1d39b3f6-21b9-4bcc-f412-1405a5de6520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count in training + validation set: 170\n",
            "Class 1 count in training + validation set: 285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d & e"
      ],
      "metadata": {
        "id": "bezasbdnT3lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(learning_rate=0.1, batch_size=10, max_iters=1000)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "train_loss, train_acc, train_prec, train_rec, train_f1 = model1.evaluate(X_train, y_train)\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = model1.evaluate(X_val, y_val)\n",
        "test_loss, test_acc, test_prec, test_rec, test_f1 = model1.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Training set: Loss = {train_loss}, Accuracy = {train_acc}, Precision = {train_prec}, Recall = {train_rec}, F1-score = {train_f1}\")\n",
        "print(f\"Validation set: Loss = {val_loss}, Accuracy = {val_acc}, Precision = {val_prec}, Recall = {val_rec}, F1-score = {val_f1}\")\n",
        "print(f\"Test set: Loss = {test_loss}, Accuracy = {test_acc}, Precision = {test_prec}, Recall = {test_rec}, F1-score = {test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqB0AsW2l3r-",
        "outputId": "55167bcd-06de-4930-fb16-c1c43e2cf23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Loss = 0.3114193793669439, Accuracy = 0.9032258064516129, Precision = 0.9593908629441624, Recall = 0.883177570093458, F1-score = 0.9197080291970803\n",
            "Validation set: Loss = 0.33800057790800325, Accuracy = 0.8508771929824561, Precision = 0.8857142857142857, Recall = 0.8732394366197183, F1-score = 0.8794326241134751\n",
            "Test set: Loss = 0.4038411571519004, Accuracy = 0.8596491228070176, Precision = 0.9516129032258065, Recall = 0.8194444444444444, F1-score = 0.8805970149253732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = LogisticRegression(learning_rate=0.001, batch_size=32, max_iters=1000)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on training, validation, and test sets\n",
        "train_loss, train_acc, train_prec, train_rec, train_f1 = model2.evaluate(X_train, y_train)\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = model2.evaluate(X_val, y_val)\n",
        "test_loss, test_acc, test_prec, test_rec, test_f1 = model2.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Training set: Loss = {train_loss}, Accuracy = {train_acc}, Precision = {train_prec}, Recall = {train_rec}, F1-score = {train_f1}\")\n",
        "print(f\"Validation set: Loss = {val_loss}, Accuracy = {val_acc}, Precision = {val_prec}, Recall = {val_rec}, F1-score = {val_f1}\")\n",
        "print(f\"Test set: Loss = {test_loss}, Accuracy = {test_acc}, Precision = {test_prec}, Recall = {test_rec}, F1-score = {test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olpH4dlzmquP",
        "outputId": "e6890518-554a-4c90-abda-d797cbc1309f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Loss = 0.8639039850716768, Accuracy = 0.7243401759530792, Precision = 0.8061224489795918, Recall = 0.7383177570093458, F1-score = 0.7707317073170732\n",
            "Validation set: Loss = 1.0615579916626554, Accuracy = 0.6403508771929824, Precision = 0.7027027027027027, Recall = 0.7323943661971831, F1-score = 0.7172413793103449\n",
            "Test set: Loss = 0.9386456117534226, Accuracy = 0.7105263157894737, Precision = 0.8095238095238095, Recall = 0.7083333333333334, F1-score = 0.7555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### f"
      ],
      "metadata": {
        "id": "Kn8--jvHUjIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 achieved better overall performance on all sets (training, validation, and test) compared to Model 2. It exhibited higher accuracy, precision, recall, and F1-score, indicating that a higher learning rate (0.1) and smaller batch size (10) improved model performance. In addition, in the context of diagnosing cancer, recall  may be more critical because it measures the model’s ability to correctly identify positive cases (cancerous instances). A high recall ensures fewer missed cancer cases, which is essential in medical diagnostics where failing to identify a cancerous instance can have serious consequences.\n"
      ],
      "metadata": {
        "id": "unsu2mImUle0"
      }
    }
  ]
}