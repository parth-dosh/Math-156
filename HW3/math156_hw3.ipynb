{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 3 - Parth Doshi, UID - 805623259"
      ],
      "metadata": {
        "id": "gia6kZB4qsSN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BtDIKzuP91P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "pfGdgsr9k55S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def cross_entropy_loss(y, t):\n",
        "    return -np.mean(t * np.log(y) + (1 - t) * np.log(1 - y))\n"
      ],
      "metadata": {
        "id": "P_3jdYbfQDC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate, batch_size, max_iters):\n",
        "      # required hyperparameters\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.max_iters = max_iters\n",
        "\n",
        "    def fit(self, X, t):\n",
        "        N, D = X.shape\n",
        "        # initialize weights to 0s\n",
        "        self.w = np.zeros(D)\n",
        "\n",
        "        for i in range(self.max_iters):\n",
        "            # shuffle rows\n",
        "            indices = np.arange(N)\n",
        "            np.random.shuffle(indices)\n",
        "            self.w = np.random.randn(D)\n",
        "            # loop through the batch size\n",
        "            for start_idx in range(0, N, self.batch_size):\n",
        "                end_idx = min(start_idx + self.batch_size, N)\n",
        "                # obtain the batch indices\n",
        "                batch_indices = indices[start_idx:end_idx]\n",
        "                # feature batch\n",
        "                X_batch = X[batch_indices]\n",
        "                # target batch\n",
        "                t_batch = t[batch_indices]\n",
        "\n",
        "                y_batch = sigmoid(np.dot(X_batch, self.w))\n",
        "\n",
        "                # average gradient of each batch\n",
        "                gradient = np.dot(X_batch.T, (y_batch - t_batch)) / len(t_batch)\n",
        "\n",
        "                # Update weights\n",
        "                self.w -= self.learning_rate * gradient\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "      # probabilities\n",
        "        return sigmoid(np.dot(X, self.w))\n",
        "\n",
        "    def predict(self, X):\n",
        "      # class label\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
        "\n",
        "    def accuracy(self, X, t):\n",
        "      \"\"\"\n",
        "\n",
        "      Compute the accuracy of the model on a given dataset.\n",
        "\n",
        "      Parameters:\n",
        "      X (array): The input features.\n",
        "      t (array): The target labels.\n",
        "\n",
        "      Returns:\n",
        "      accuracy (float): The accuracy of the model.\n",
        "      \"\"\"\n",
        "      predictions = self.predict(X)\n",
        "      return np.mean(predictions == t)\n",
        "\n",
        "    def confusion_mat(self, y_true, y_pred):\n",
        "      \"\"\"\n",
        "      Compute the confusion matrix for binary classification.\n",
        "\n",
        "      Parameters:\n",
        "      y_true (array-like): The true binary labels (0 or 1).\n",
        "      y_pred (array-like): The predicted binary labels (0 or 1).\n",
        "\n",
        "      Returns:\n",
        "      TP (int): True Positives\n",
        "      FP (int): False Positives\n",
        "      FN (int): False Negatives\n",
        "      TN (int): True Negatives\n",
        "      \"\"\"\n",
        "      TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "      TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "      FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "      FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "      return TP, FP, FN, TN\n",
        "\n",
        "    def precision_recall_f1(self, y_true, y_pred):\n",
        "      \"\"\"\n",
        "      Compute the precision, recall, and F1-score for binary classification.\n",
        "      Parameters:\n",
        "      y_true (array-like): The true binary labels (0 or 1).\n",
        "      y_pred (array-like): The predicted binary labels (0 or 1).\n",
        "      Returns:\n",
        "      precision (float): The precision value.\n",
        "      recall (float): The recall value.\n",
        "      f1 (float): The F1-score value.\n",
        "      \"\"\"\n",
        "      TP, FP, FN, TN = self.confusion_mat(y_true, y_pred)\n",
        "\n",
        "      # Precision\n",
        "      precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "      # Recall\n",
        "      recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "      # F1-Score\n",
        "      f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "      return precision, recall, f1\n",
        "\n",
        "    def evaluate(self, X, t):\n",
        "      \"\"\"\n",
        "      Evaluate the model on a given dataset.\n",
        "\n",
        "      Parameters:\n",
        "      X (array): The input features.\n",
        "      t (array): The target labels.\n",
        "\n",
        "      Returns:\n",
        "      loss (float): The cross-entropy loss\n",
        "      accuracy (float): The accuracy of the model\n",
        "      precision (float): The precision of the model\n",
        "      recall (float): The recall of the model\n",
        "      f1 (float): The F1-score of the model\n",
        "      \"\"\"\n",
        "      y_pred = self.predict(X)\n",
        "      y_prob = self.predict_proba(X)\n",
        "\n",
        "      loss = cross_entropy_loss(y_prob, t)\n",
        "      accuracy = self.accuracy(X, t)\n",
        "\n",
        "      precision, recall, f1 = self.precision_recall_f1(t, y_pred)\n",
        "\n",
        "      return loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "6DjhAhe3RnDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "Tgbl_yIdk-VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a"
      ],
      "metadata": {
        "id": "eTRC05tOTpYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "cancer = load_breast_cancer()\n"
      ],
      "metadata": {
        "id": "AyQ9jOfPUbOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b"
      ],
      "metadata": {
        "id": "ZwsetYOiTq2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the training data\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apply the same transformation to validation and test data\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "-kVni5XcUxWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c"
      ],
      "metadata": {
        "id": "V8zBPTnUTuYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_combined = np.concatenate([y_train, y_val])\n",
        "\n",
        "# Report the size of each class\n",
        "class_0_count = sum(y_train_combined == 0)\n",
        "class_1_count = sum(y_train_combined == 1)\n",
        "\n",
        "print(f\"Class 0 count in training + validation set: {class_0_count}\")\n",
        "print(f\"Class 1 count in training + validation set: {class_1_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TKrB1mElWId",
        "outputId": "1d39b3f6-21b9-4bcc-f412-1405a5de6520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 count in training + validation set: 170\n",
            "Class 1 count in training + validation set: 285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d & e"
      ],
      "metadata": {
        "id": "bezasbdnT3lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(learning_rate=0.1, batch_size=10, max_iters=1000)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "train_loss, train_acc, train_prec, train_rec, train_f1 = model1.evaluate(X_train, y_train)\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = model1.evaluate(X_val, y_val)\n",
        "test_loss, test_acc, test_prec, test_rec, test_f1 = model1.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Training set: Loss = {train_loss}, Accuracy = {train_acc}, Precision = {train_prec}, Recall = {train_rec}, F1-score = {train_f1}\")\n",
        "print(f\"Validation set: Loss = {val_loss}, Accuracy = {val_acc}, Precision = {val_prec}, Recall = {val_rec}, F1-score = {val_f1}\")\n",
        "print(f\"Test set: Loss = {test_loss}, Accuracy = {test_acc}, Precision = {test_prec}, Recall = {test_rec}, F1-score = {test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqB0AsW2l3r-",
        "outputId": "55167bcd-06de-4930-fb16-c1c43e2cf23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Loss = 0.3114193793669439, Accuracy = 0.9032258064516129, Precision = 0.9593908629441624, Recall = 0.883177570093458, F1-score = 0.9197080291970803\n",
            "Validation set: Loss = 0.33800057790800325, Accuracy = 0.8508771929824561, Precision = 0.8857142857142857, Recall = 0.8732394366197183, F1-score = 0.8794326241134751\n",
            "Test set: Loss = 0.4038411571519004, Accuracy = 0.8596491228070176, Precision = 0.9516129032258065, Recall = 0.8194444444444444, F1-score = 0.8805970149253732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = LogisticRegression(learning_rate=0.001, batch_size=32, max_iters=1000)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on training, validation, and test sets\n",
        "train_loss, train_acc, train_prec, train_rec, train_f1 = model2.evaluate(X_train, y_train)\n",
        "val_loss, val_acc, val_prec, val_rec, val_f1 = model2.evaluate(X_val, y_val)\n",
        "test_loss, test_acc, test_prec, test_rec, test_f1 = model2.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"Training set: Loss = {train_loss}, Accuracy = {train_acc}, Precision = {train_prec}, Recall = {train_rec}, F1-score = {train_f1}\")\n",
        "print(f\"Validation set: Loss = {val_loss}, Accuracy = {val_acc}, Precision = {val_prec}, Recall = {val_rec}, F1-score = {val_f1}\")\n",
        "print(f\"Test set: Loss = {test_loss}, Accuracy = {test_acc}, Precision = {test_prec}, Recall = {test_rec}, F1-score = {test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olpH4dlzmquP",
        "outputId": "e6890518-554a-4c90-abda-d797cbc1309f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Loss = 0.8639039850716768, Accuracy = 0.7243401759530792, Precision = 0.8061224489795918, Recall = 0.7383177570093458, F1-score = 0.7707317073170732\n",
            "Validation set: Loss = 1.0615579916626554, Accuracy = 0.6403508771929824, Precision = 0.7027027027027027, Recall = 0.7323943661971831, F1-score = 0.7172413793103449\n",
            "Test set: Loss = 0.9386456117534226, Accuracy = 0.7105263157894737, Precision = 0.8095238095238095, Recall = 0.7083333333333334, F1-score = 0.7555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### f"
      ],
      "metadata": {
        "id": "Kn8--jvHUjIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 achieved better overall performance on all sets (training, validation, and test) compared to Model 2. It exhibited higher accuracy, precision, recall, and F1-score, indicating that a higher learning rate (0.1) and smaller batch size (10) improved model performance. In addition, in the context of diagnosing cancer, recall  may be more critical because it measures the modelâ€™s ability to correctly identify positive cases (cancerous instances). A high recall ensures fewer missed cancer cases, which is essential in medical diagnostics where failing to identify a cancerous instance can have serious consequences.\n"
      ],
      "metadata": {
        "id": "unsu2mImUle0"
      }
    }
  ]
}